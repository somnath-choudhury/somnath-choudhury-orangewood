1) Are you adding any augmentations to the dataset. If yes, then which ones and why. If not, then why not?
Ans) Saturation: Between -25% and +25%
 Brightness: Between -15% and +15%
 Exposure: Between -10% and +10%
 Noise: Up to 0.1% of pixels

These adjustments indicate a controlled augmentation strategy to introduce variability to the dataset without making drastic changes to the images.

 Saturation: Adjusting saturation within -25% to +25% adds variability to color intensity in the images.
 Brightness: Changing brightness between -15% and +15% mimics varying lighting conditions, which helps the model learn to recognize features in both dim and well-lit situations.

 Exposure: Adjusting exposure by -10% to +10% helps the model adapt to minor changes in image exposure that can occur due to camera settings or ambient light fluctuations.

Noise: Adding noise (up to 0.1% of pixels) introduces slight randomness, simulating the minor imperfections found in real-world images. 

2) How many epochs are you using for this dataset training?

Ans) epochs = 20  # No of Epochs
batch = 16    # Batch Size
lr0 = 0.01   # Learning Rate
imgsz = 320  # Image Sizw

- Epochs: Chose 20 epochs to provide the model enough time to learn the features of the dataset.
- Batch Size: A batch size of 16 is used to balance memory usage and model performance.
- Learning Rate: Set to 0.01 for stable convergence during training.

3) List any other hyperparameters you are specifying while training. Give reasoning for same.

Ans) a)Learning Rate:

Controls the step size during gradient descent. A low learning rate can make the training process slow, while a high learning rate might cause the model to converge prematurely or oscillate around the optimal solution. Often chosen through experimentation or hyperparameter tuning techniques.

b) Batch Size:
Refers to the number of training samples processed before the model updates. Smaller batch sizes can lead to more noisy estimates of the gradient, which can sometimes help the model generalize better but may increase training time. Larger batch sizes tend to smooth gradients, which can stabilize training but may require more memory.

c) Number of Epochs:
Indicates how many times the entire training dataset is passed through the model. Too few epochs may lead to underfitting, while too many could lead to overfitting. Early stopping can be used to terminate training when validation performance ceases to improve.

d) Dropout Rate:
The fraction of neurons randomly set to zero during training. This helps prevent overfitting by encouraging the network to learn robust features. A typical dropout rate ranges between 0.2 to 0.5 for dense layers, depending on the complexity of the model and the amount of data available.

4) What output metrices are you analysing. Share concrete results from those.

Ans) To understand the model's performance, we use measures such as Precision, Recall, mAP@50, and mAP@50:95.
# These metrics give information on how well the model recognises and classifies things in the photos.
**Precision** refers to the precision of positive forecasts.
**Recall** determines how many true positives are collected.
**mAP@50** (mean average precision at IOU threshold 0.5) is a common statistic for object detection performance.
**mAP@50:95** calculates the mean AP across various IOU thresholds, providing a more thorough perspective of performance.